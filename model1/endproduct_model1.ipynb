{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ninagroot/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk \n",
    "import requests\n",
    "import json\n",
    "import googletrans\n",
    "import random\n",
    "import re\n",
    "\n",
    "from random import randint\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from spacy.lang.en import English\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import wordnet \n",
    "from googletrans import Translator\n",
    "\n",
    "spacy.load('en_core_web_sm')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "parser = English()\n",
    "porter = PorterStemmer()\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-594b1a29d907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'edit-db_model1.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_gratitude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gratitude'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_exercises\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exercises_model1.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_journal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prepared_journal_model1_lang.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df_journal = df_journal.dropna(subset = ['id'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "file = 'edit-db_model1.xlsx'\n",
    "df_gratitude = pd.read_excel(file, 'gratitude')\n",
    "df_exercises = pd.read_excel('exercises_model1.xlsx')\n",
    "df_journal = pd.read_excel('prepared_journal_model1_lang.xlsx')\n",
    "#df_journal = df_journal.dropna(subset = ['id'])\n",
    "\n",
    "topics = {\n",
    "    'social media': ['social', 'media', 'network', 'twitter', 'facebook', 'instagram', 'web', 'linkedin', 'google', 'viral', 'google+', 'event', 'website', 'reach', 'telegraph', 'telephone', 'blog', 'internet', 'social', 'sociality', 'technoself', 'intranet', 'cyber', 'business', 'sociable', 'activist', 'microblogging', 'socially', 'cybernetic', 'pinterest', 'youtube', 'tumblr', 'cyberspace', 'extranet', 'telnet', 'cybernetics', 'modem', 'communication', 'informatics', 'virtual', 'party', 'picture'],\n",
    "    'body insecurity': ['body', 'insecure', 'belly', 'skin', 'waist', 'hair', 'eyes', 'lips', 'ears', 'forehead', 'eyebrow', 'chin', 'scar', 'nose', 'look', 'eat', 'ate', 'boldness', 'beard', 'smile', 'teeth', 'stomach', 'back', 'ass', 'butt', 'frame', 'feature', 'physique', 'bod', 'bodies', 'torso', 'arm', 'head', 'corpse', 'chest', 'shape', 'shoulder', 'form', 'neck', 'structure', 'leg', 'mass', 'weight', 'shaky', 'unattractive', 'unsure', 'anxious', 'jealous', 'unconfident', 'distrustful', 'uncomfortable', 'unsecured', 'neurotic', 'hopeless', 'depressed', 'introverted', 'helpless', 'fragile', 'danger', 'anxiety', 'mistrust', 'instability', 'unrest', 'hardship', 'vulnerability', 'lawlessness', 'uncertainty', 'turmoil', 'strife', 'fragility', 'hopelessness', 'malnutrition', 'alienation', 'violence', 'poverty', 'tension', 'shortages', 'despair', 'chaos', 'distrust', 'resentment', 'underdevelopment', 'anarchy', 'paranoia', 'cynicism', 'fear', 'scared', 'insecure', 'fearful'],\n",
    "    'social anxiety': ['fear', 'worry', 'stress', 'nervousness', 'attention', 'shame', 'panic', 'social', 'attack', 'own', 'activities', 'lonely', 'alone', 'rejection', 'distance', 'careful', 'courage', 'conversation',  'afraid', 'mistake', 'stupid', 'insecurity', 'public', 'speaking', 'nausea', 'stutter', 'acting', 'performance', 'stage', 'fright', 'fear', 'public', 'shyness', 'blushing', 'anxiety', 'self-consciousness', 'panic', 'illness', 'mood disorder', 'timidness', 'social functioning', 'parties', 'outgoing', 'street', 'public', 'shyness', 'blushing', 'anxiety', 'self-consciousness', 'panic', 'illness', 'mood disorder', 'timidness', 'street', 'outside', 'social functioning', 'parties', 'outgoing', 'illness', 'peer rejection', 'stutter', 'stage fright', 'guilt', 'panic attack'],\n",
    "    'friendship' : ['best', 'friend', 'classmate', 'schoolmate', 'roomie', 'boyfriend', 'sister', 'amigo', 'acquanitance', 'brother', 'comerade', 'girlfriend', 'person', 'pal', 'schoolfriend', 'mate', 'colleague', 'roommate', 'love', 'pal', 'buddy', 'talk', 'soulmate', 'fight', 'trust', 'understanding', 'happiness', 'relations', 'empathy', 'company', 'feelings', 'unity', 'friendship', 'friend', 'companionship', 'relationship', 'affection', 'break', 'broke']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4b97aeecc0dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_journal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal' is not defined"
     ]
    }
   ],
   "source": [
    "display(df_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def lemma1(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "def lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word,'v')\n",
    "\n",
    "def prepare_text(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 2] #check what works best \n",
    "    #tokens = [porter.stem(token) for token in tokens] #stemming\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [lemma1(token) for token in tokens] #lemmatization \n",
    "    tokens = [lemma2(token) for token in tokens] #lemmatization verbs\n",
    "    return tokens\n",
    "\n",
    "def prepare_topics(topics):\n",
    "    for topic in topics: \n",
    "        prepared_words = [] \n",
    "        for string in topics[topic]:\n",
    "            string = prepare_text(string)\n",
    "            prepared_words.append(string)\n",
    "            res = []\n",
    "            [res.append(x) for x in prepared_words if x not in res] \n",
    "            res = [' '.join(map(str, i)) for i in res]\n",
    "        topics[topic] = res\n",
    "    return topics \n",
    "\n",
    "def prepare_tag(tag): \n",
    "    tokens = tokenize(tag)\n",
    "    tokens = [token for token in tokens if len(token) > 2] \n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [lemma1(token) for token in tokens]  \n",
    "    tokens = [lemma2(token) for token in tokens] \n",
    "    return tokens\n",
    "\n",
    "def sentiment_analyzer(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    negative_score = score['neg']\n",
    "    positive_score = score['pos']\n",
    "    neutral_score = score['neu']\n",
    "    difference = abs(negative_score - positive_score)\n",
    "    if neutral_score > 0.8:\n",
    "        return 'neutral'\n",
    "    elif difference <0.1:\n",
    "        return 'neutral'\n",
    "    elif negative_score > positive_score:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "def dutch_translator(text):\n",
    "    result = translator.translate(text, dest='en',  src='nl')\n",
    "    return result.text\n",
    "\n",
    "def eng_translator(text):\n",
    "    result = translator.translate(text, dest='nl',  src='en')\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a0e0f1d09e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepared_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prepared_tag'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepare_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "prepared_topics = prepare_topics(topics)\n",
    "df_journal['prepared_tag'] = df_journal.apply(lambda row: prepare_tag(row.tag), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_topic_tag(text, tag, prepared_topics):\n",
    "    sim_scores = [] \n",
    "    for topic in prepared_topics:\n",
    "        sim_score = 0    \n",
    "        for word in prepared_topics[topic]:\n",
    "            if word in text:\n",
    "                if word != '':\n",
    "                    occurences = text.count(word)\n",
    "                    sim_score += occurences\n",
    "\n",
    "            if word in tag: \n",
    "                if word != '':\n",
    "                    sim_score += 3\n",
    "                    \n",
    "        tokenized_topic = tokenize(topic)\n",
    "        for word in tokenized_topic:\n",
    "            if word in tag:\n",
    "                   sim_score += 6\n",
    "\n",
    "        sim_scores.append(sim_score)\n",
    "    highest_score = max(sim_scores)\n",
    "    if highest_score < 3:\n",
    "        return 'no topic'\n",
    "    else:\n",
    "        index_highest_score = list_duplicates_of(sim_scores, highest_score)\n",
    "\n",
    "        chosen_topics = [] \n",
    "        for i in index_highest_score:\n",
    "            topic =  list(prepared_topics)[i]\n",
    "            chosen_topics.append(topic.strip()) \n",
    "        return chosen_topics\n",
    "\n",
    "def list_duplicates_of(seq,item):\n",
    "    start_at = -1\n",
    "    locs = []\n",
    "    while True:\n",
    "        try:\n",
    "            loc = seq.index(item,start_at+1)\n",
    "        except ValueError:\n",
    "            break\n",
    "        else:\n",
    "            locs.append(loc)\n",
    "            start_at = loc\n",
    "    return locs\n",
    "\n",
    "def social_media_score(text, tag, prepared_topics):\n",
    "    sim_scores = []\n",
    "    for topic in prepared_topics:\n",
    "        sim_score = 0    \n",
    "        for word in prepared_topics[topic]:\n",
    "            if word in text:\n",
    "                if word != '':\n",
    "                    occurences = text.count(word)\n",
    "                    sim_score += occurences\n",
    "\n",
    "            if word in tag: \n",
    "                if word != '':\n",
    "                    sim_score += 3\n",
    "                    \n",
    "        tokenized_topic = tokenize(topic)\n",
    "        for word in tokenized_topic:\n",
    "            if word in tag:\n",
    "                   sim_score += 6\n",
    "        sim_scores.append(sim_score)\n",
    "    return sim_scores[0]\n",
    "\n",
    "def body_insecurity_score(text, tag, prepared_topics):\n",
    "    sim_scores = []\n",
    "    for topic in prepared_topics:\n",
    "        sim_score = 0    \n",
    "        for word in prepared_topics[topic]:\n",
    "            if word in text:\n",
    "                if word != '':\n",
    "                    occurences = text.count(word)\n",
    "                    sim_score += occurences\n",
    "\n",
    "            if word in tag: \n",
    "                if word != '':\n",
    "                    sim_score += 3\n",
    "                    \n",
    "        tokenized_topic = tokenize(topic)\n",
    "        for word in tokenized_topic:\n",
    "            if word in tag:\n",
    "                   sim_score += 6\n",
    "        sim_scores.append(sim_score)\n",
    "    return sim_scores[1]\n",
    "\n",
    "def social_anxiety_score(text, tag, prepared_topics):\n",
    "    sim_scores = []\n",
    "    for topic in prepared_topics:\n",
    "        sim_score = 0    \n",
    "        for word in prepared_topics[topic]:\n",
    "            if word in text:\n",
    "                if word != '':\n",
    "                    occurences = text.count(word)\n",
    "                    sim_score += occurences\n",
    "\n",
    "            if word in tag: \n",
    "                if word != '':\n",
    "                    sim_score += 3\n",
    "                    \n",
    "        tokenized_topic = tokenize(topic)\n",
    "        for word in tokenized_topic:\n",
    "            if word in tag:\n",
    "                   sim_score += 6\n",
    "        sim_scores.append(sim_score)\n",
    "    return sim_scores[2]\n",
    "\n",
    "def friendship_score(text, tag, prepared_topics):\n",
    "    sim_scores = []\n",
    "    for topic in prepared_topics:\n",
    "        sim_score = 0    \n",
    "        for word in prepared_topics[topic]:\n",
    "            if word in text:\n",
    "                if word != '':\n",
    "                    occurences = text.count(word)\n",
    "                    sim_score += occurences\n",
    "\n",
    "            if word in tag: \n",
    "                if word != '':\n",
    "                    sim_score += 3\n",
    "                    \n",
    "        tokenized_topic = tokenize(topic)\n",
    "        for word in tokenized_topic:\n",
    "            if word in tag:\n",
    "                   sim_score += 6\n",
    "        sim_scores.append(sim_score)\n",
    "    return sim_scores[3]\n",
    "\n",
    "\n",
    "def find_sentiment(text):\n",
    "    sentiment = sentiment_analyzer(text)\n",
    "    return sentiment \n",
    "\n",
    "def add_topic_score_to_df(prepared_topics, df_journal):\n",
    "    df_journal['social_media'] = df_journal.apply(lambda row: social_media_score(row.prepared_description, row.prepared_tag, prepared_topics), axis = 1)\n",
    "    df_journal['body_insecurity'] = df_journal.apply(lambda row: body_insecurity_score(row.prepared_description, row.prepared_tag, prepared_topics), axis = 1)\n",
    "    df_journal['social_anxiety'] = df_journal.apply(lambda row: social_anxiety_score(row.prepared_description, row.prepared_tag, prepared_topics), axis = 1)\n",
    "    df_journal['friendship'] = df_journal.apply(lambda row: friendship_score(row.prepared_description, row.prepared_tag, prepared_topics), axis = 1)\n",
    "    df_journal['topic'] = df_journal.apply(lambda row: find_topic_tag(row.prepared_description, row.prepared_tag, prepared_topics), axis = 1)\n",
    "    df_journal['sentiment'] = df_journal.apply(lambda row: find_sentiment(row.description_eng), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepared_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f62ef4b3c498>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madd_topic_score_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'check_topics'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'check_topics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepared_topics' is not defined"
     ]
    }
   ],
   "source": [
    "add_topic_score_to_df(prepared_topics, df_journal)\n",
    "df_journal['check_topics'] = df_journal.apply(lambda row: row.gold_label in row.topic, axis=1)\n",
    "score = df_journal['check_topics'].value_counts()\n",
    "correct = score[1]\n",
    "incorrect = score[0]\n",
    "percentage_correct = round(((correct/len(df_journal))*100), 2)\n",
    "percentage_incorrect = round(((incorrect/len(df_journal))*100), 2)\n",
    "print('The number of correct classifications is:', correct, '. This is', percentage_correct, 'percent of the total amount.', '\\nThe number of incorrect classifications is:', incorrect, '. This is', percentage_incorrect, 'percent of the total amount.')\n",
    "display(df_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-27b62f0bfd95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_journal_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gold_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'no topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'check_topics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal' is not defined"
     ]
    }
   ],
   "source": [
    "df_journal_topics = df_journal.loc[df_journal['gold_label'] != 'no topic']\n",
    "score = df_journal_topics['check_topics'].value_counts()\n",
    "print(score)\n",
    "correct = score[1]\n",
    "incorrect = score[0]\n",
    "percentage_correct = round(((correct/len(df_journal_topics))*100), 2)\n",
    "percentage_incorrect = round(((incorrect/len(df_journal_topics))*100), 2)\n",
    "print('The number of correct classifications is:', correct, '. This is', percentage_correct, 'percent of the total amount.', '\\nThe number of incorrect classifications is:', incorrect, '. This is', percentage_incorrect, 'percent of the total amount.')\n",
    "display(df_journal_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fe350a86fe4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_journal_topics1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_topics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gold_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'social anxiety'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_topics1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'check_topics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mincorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal_topics' is not defined"
     ]
    }
   ],
   "source": [
    "df_journal_topics1 = df_journal_topics.loc[df_journal['gold_label'] == 'social anxiety']\n",
    "score = df_journal_topics1['check_topics'].value_counts()\n",
    "print(score)\n",
    "correct = score[1]\n",
    "incorrect = score[0]\n",
    "percentage_correct = round(((correct/len(df_journal_topics1))*100), 2)\n",
    "percentage_incorrect = round(((incorrect/len(df_journal_topics1))*100), 2)\n",
    "print('The number of correct classifications is:', correct, '. This is', percentage_correct, 'percent of the total amount.', '\\nThe number of incorrect classifications is:', incorrect, '. This is', percentage_incorrect, 'percent of the total amount.')\n",
    "display(df_journal_topics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f23d8a563294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_journal_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gold_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'no topic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#df_journal_topics = df_journal_topics.loc[df_journal_topics['check_topics'] == 'False']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_topics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'check_topics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal' is not defined"
     ]
    }
   ],
   "source": [
    "df_journal_topics = df_journal.loc[df_journal['gold_label'] == 'no topic']\n",
    "#df_journal_topics = df_journal_topics.loc[df_journal_topics['check_topics'] == 'False']\n",
    "score = df_journal_topics['check_topics'].value_counts()\n",
    "print(score)\n",
    "correct = score[1]\n",
    "incorrect = score[0]\n",
    "percentage_correct = round(((correct/len(df_journal_topics))*100), 2)\n",
    "percentage_incorrect = round(((incorrect/len(df_journal_topics))*100), 2)\n",
    "print('The number of correct classifications is:', correct, '. This is', percentage_correct, 'percent of the total amount.', '\\nThe number of incorrect classifications is:', incorrect, '. This is', percentage_incorrect, 'percent of the total amount.')\n",
    "display(df_journal_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4606ae81d6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gold_label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal' is not defined"
     ]
    }
   ],
   "source": [
    "df_journal.groupby(by='gold_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e818f31293dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchosen_question_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mquestion_for_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_exercises\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal' is not defined"
     ]
    }
   ],
   "source": [
    "#kijkt naar het percentage van de punten per topic en de kans op een topic is even groot als dit percentage (met 20% willekeurig)\n",
    "def topics_per_user1(df_journal, df_exercises, user_id):\n",
    "    list1 = []\n",
    "    list1.append(user_id)\n",
    "    df_journal = df_journal[df_journal.id_user.isin(list1)]\n",
    "    topic_df = df_journal[['social_media', 'social_anxiety', 'body_insecurity', 'friendship']]\n",
    "    topics = list(topic_df.columns)\n",
    "    sum_df = topic_df.sum()\n",
    "    total = sum_df.sum()\n",
    "    percentages = []\n",
    "    for i in sum_df:\n",
    "        percentage = (i / total * 100)\n",
    "        percentages.append(percentage)\n",
    "    percentages1 = np.cumsum(percentages)\n",
    "    dicts = dict(zip(topics, percentages1))    \n",
    "    sorted_dict = dict(sorted(dicts.items(), key=lambda item: item[1]))\n",
    "    random1 = randint(0,100)\n",
    "    if random1 < list(sorted_dict.values())[0]: \n",
    "        chosen_topic1 = list(sorted_dict.keys())[0]\n",
    "    elif random1 < list(sorted_dict.values())[1]: \n",
    "        chosen_topic1 = list(sorted_dict.keys())[1]\n",
    "    elif random1 < list(sorted_dict.values())[2]: \n",
    "        chosen_topic1 = list(sorted_dict.keys())[2]\n",
    "    elif random1 < list(sorted_dict.values())[3]: \n",
    "        chosen_topic1 = list(sorted_dict.keys())[3]\n",
    "    else: \n",
    "        chosen_topic1 = random.choice(topics)\n",
    "    chosen_question_id = return_questions1(df_exercises, user_id, chosen_topic1)\n",
    "    return chosen_question_id\n",
    "\n",
    "def pick_random_question(all_ids, likely_ids):\n",
    "    random_nr = random.uniform(0, 1)\n",
    "    if random_nr > 0.8:\n",
    "        chosen_question = random.choice(all_ids)\n",
    "    else:\n",
    "        chosen_question = random.choice(likely_ids)\n",
    "    return chosen_question \n",
    "\n",
    "def return_questions1(df_exercises, user_id, chosen_topic1):\n",
    "    df = df_exercises[df_exercises.Topic == chosen_topic1]\n",
    "    all_ids = list(df_exercises['ID'])\n",
    "    likely_ids = list(df['ID'])\n",
    "    chosen_question_id = pick_random_question(all_ids, likely_ids)\n",
    "    return(chosen_question_id)\n",
    "\n",
    "def question_for_user(user_id, df_journal, df_exercises):\n",
    "    chosen_question_id = topics_per_user1(df_journal, df_exercises, user_id)\n",
    "    print(chosen_question_id)\n",
    "\n",
    "question_for_user(11, df_journal, df_exercises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dutch_topics = [] \n",
    "all_topics = ['social media', 'social anxiety', 'body insecurity', 'friendship']\n",
    "for topic in all_topics:\n",
    "    topic = eng_translator(topic)\n",
    "    all_dutch_topics.append(topic)\n",
    "\n",
    "df_journal_did = df_journal[df_journal.type == 'did']\n",
    "df_journal_wish = df_journal[df_journal.type == 'wish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['social_media', 'social_anxiety', 'body_insecurity', 'friendship'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d583295099b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mcomment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_dutch_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mcomment_for_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_journal_did\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_dutch_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-d583295099b5>\u001b[0m in \u001b[0;36mcomment_for_user\u001b[0;34m(user_id, df_journal_did, all_topics_dutch)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcomment_for_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_journal_did\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_topics_dutch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdf_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_did\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_journal_did\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_user\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtopic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_user\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'social_media'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'social_anxiety'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body_insecurity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'friendship'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0msum_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopic_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mgood_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['social_media', 'social_anxiety', 'body_insecurity', 'friendship'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#did/wish toevoegen en comment \n",
    "def comment(user_id, good_topics, all_dutch_topics):\n",
    "    good_topics_dutch = []\n",
    "    for topic in good_topics: \n",
    "        topic = topic.replace('_', ' ')\n",
    "        topic = eng_translator(topic)\n",
    "        good_topics_dutch.append(topic)\n",
    "\n",
    "    less_topics = [x for x in all_dutch_topics if x not in good_topics_dutch]\n",
    " \n",
    "    if len(less_topics) == 0:\n",
    "        print('We merken dat je zelfcompassie al erg goed toepast, ga zo door!')\n",
    "    elif len(good_topics) == 0:\n",
    "        print('Probeer zelfcompassie toe te passen in je dagelijke leven!')\n",
    "    elif len(good_topics) == 1:\n",
    "        less_topic = random.choice(less_topics)\n",
    "        print('Goed bezig! We merken dat je zelfcompassie al goed toepast of het gebied van', good_topics_dutch[0], ', probeer zelfcompassie ook eens toe te passen op het gebied van', less_topic, '!' )\n",
    "    elif len(good_topics) == 2:\n",
    "        less_topic = random.choice(less_topics)\n",
    "        print('Goed bezig! We merken dat je zelfcompassie al goed toepast of het gebied van', good_topics_dutch[0], 'en', good_topics_dutch[1], '! Probeer zelfcompassie ook eens toe te passen op het gebied van', less_topic, '.' )\n",
    "    elif len(good_topics) == 3: \n",
    "        less_topic = random.choice(less_topics)\n",
    "        print('Goed bezig! We merken dat je zelfcompassie al goed toepast of het gebied van', good_topics_dutch[0], ', ', good_topics_dutch[1], 'en', good_topics_dutch[2], '! Probeer zelfcompassie ook eens toe te passen op het gebied van', less_topic, '.' )\n",
    "\n",
    "def comment_for_user(user_id, df_journal_did, all_topics_dutch): \n",
    "    df_user = df_journal_did[df_journal_did.id_user == user_id]\n",
    "    topic_df = df_user[['social_media', 'social_anxiety', 'body_insecurity', 'friendship']]\n",
    "    sum_df = topic_df.sum()\n",
    "    good_topics = []\n",
    "    for i in range(len(sum_df)): \n",
    "        if sum_df[i] > 2:\n",
    "            good_topics.append(topic_df.columns[i])\n",
    "    comment(user_id, good_topics, all_dutch_topics)\n",
    "        \n",
    "comment_for_user(13, df_journal_did, all_dutch_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal_did' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0eb8ee78afc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_journal_did\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal_did' is not defined"
     ]
    }
   ],
   "source": [
    "display(df_journal_did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "results =translator.translate('हॅलो वर्ल्ड')\n",
    "print(results.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
