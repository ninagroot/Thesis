{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ninagroot/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk \n",
    "import requests\n",
    "import json\n",
    "import googletrans\n",
    "import random\n",
    "\n",
    "from random import randint\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from spacy.lang.en import English\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import wordnet \n",
    "from googletrans import Translator\n",
    "\n",
    "spacy.load('en_core_web_sm')\n",
    "nltk.download('stopwords')\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "parser = English()\n",
    "porter = PorterStemmer()\n",
    "translator = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'edit-db_model2.xlsx'\n",
    "df_gratitude = pd.read_excel(file, 'gratitude')\n",
    "#df_exercises = pd.read_excel('exercises_model2.xlsx')\n",
    "df_journal = pd.read_excel(file, 'sc_journal')\n",
    "\n",
    "topics = {\n",
    "    'social media': ['social', 'media', 'network', 'twitter', 'facebook', 'instagram', 'web', 'linkedin', 'google', 'viral', 'google+', 'event', 'website', 'reach', 'telegraph', 'telephone', 'blog', 'internet', 'social', 'sociality', 'technoself', 'intranet', 'cyber', 'business', 'sociable', 'activist', 'microblogging', 'socially', 'cybernetic', 'pinterest', 'youtube', 'tumblr', 'cyberspace', 'extranet', 'telnet', 'cybernetics', 'modem', 'communication', 'informatics', 'virtual', 'party', 'picture'],\n",
    "    'body insecurity': ['body insecurity', 'body', 'insecure', 'belly', 'skin', 'waist', 'hair', 'eyes', 'lips', 'ears', 'forehead', 'eyebrow', 'chin', 'scar', 'nose', 'look', 'eat', 'ate', 'boldness', 'beard', 'smile', 'teeth', 'stomach', 'back', 'ass', 'butt', 'frame', 'feature', 'physique', 'bod', 'bodies', 'torso', 'arm', 'head', 'corpse', 'chest', 'shape', 'shoulder', 'form', 'neck', 'structure', 'leg', 'mass', 'weight', 'shaky', 'unattractive', 'unsure', 'anxious', 'jealous', 'unconfident', 'distrustful', 'uncomfortable', 'unsecured', 'neurotic', 'hopeless', 'depressed', 'introverted', 'helpless', 'fragile', 'danger', 'anxiety', 'mistrust', 'instability', 'unrest', 'hardship', 'vulnerability', 'lawlessness', 'uncertainty', 'turmoil', 'strife', 'fragility', 'hopelessness', 'malnutrition', 'alienation', 'violence', 'poverty', 'tension', 'shortages', 'despair', 'chaos', 'distrust', 'resentment', 'underdevelopment', 'anarchy', 'paranoia', 'cynicism', 'fear', 'scared', 'insecure', 'fearful'],\n",
    "    'social anxiety': ['social anxiety', 'shyness', 'blushing', 'fear', 'worry', 'stress', 'nervousness', 'attention', 'shame', 'panic', 'social', 'attack', 'own', 'activities', 'lonely', 'alone', 'rejection', 'public', 'speaking', 'nausea', 'stutter', 'acting', 'performance', 'stage', 'fright', 'fear', 'public', 'shyness', 'blushing', 'anxiety', 'self-consciousness', 'panic', 'illness', 'mood disorder', 'timidness', 'social functioning', 'parties', 'outgoing', 'illness', 'peer rejection', 'stutter', 'stage fright', 'guilt', 'panic attack'],\n",
    "    'relationships' : ['friendship', 'best', 'friend', 'classmate', 'schoolmate', 'roomie', 'boyfriend', 'sister', 'amigo', 'acquanitance', 'brother', 'comerade', 'girlfriend', 'person', 'pal', 'schoolfriend', 'mate', 'colleague', 'roommate', 'love', 'pal', 'buddy', 'talk', 'soulmate', 'fight', 'trust', 'understanding', 'happiness', 'relations', 'empathy', 'company', 'feelings', 'unity', 'friendship', 'friend', 'companionship', 'relationship', 'relation', 'friendship', 'affinity', 'kinship', 'affiliation', 'association', 'partnership', 'acquaintance', 'state', 'consanguinity', 'sisterhood', 'brotherhood', 'membership', 'human relationship', 'family relationship', 'relate', 'relational', 'interrelation', 'family', 'partner', 'relatedness', 'relatedness', 'correlate', 'parentage', 'relative', 'tie', 'account', 'involvement', 'ties', 'affair', 'engagement', 'contacts', 'rapport', 'connection', 'dealing', 'terms', 'regards', 'concerned', 'comparison', 'linkage', 'motherhood', 'maternity', 'paternity', 'fatherhood', 'subjection', 'birth', 'romance', 'life', 'understanding', 'shared', 'future', 'complicated', 'marriage', 'ally', 'feelings', 'intereseted', 'personality', 'mutual', 'personal', 'incest', 'foster', 'absence', 'bilateral', 'sense', 'resolve', 'cousin', 'business relationship', 'love affair', 'personal relation', 'friendly relationship', 'blood kinship', 'marital bed', 'line of descent', 'sexual relationship', 'marital relationship', 'phylogenetic relationship', 'aunt', 'familial', 'fraternal', 'sister', 'nephew', 'grandniece', 'analogy', 'siblinghood', 'framily', 'brother', 'heteronymous', 'neighbourship', 'granddaughter', 'nieceship', 'niece', 'kiss cousin', 'social relation', 'stepbrother', 'intimacy', 'uncle', 'spousal', 'stepsister', 'familywise', 'hookup', 'nonmarriage', 'private life', 'stepfamily', 'interaction', 'lust', 'platonic love', 'affection', 'kindness', 'pleasure', 'compassion', 'sex', 'hate', 'heart', 'emotion', 'religion', 'sexual attraction', 'passion', 'lover', 'fight', 'lie'],\n",
    "    'work': ['work', 'job', 'turn', 'ferment', 'exercise', 'play', 'sour', 'work out', 'labor', 'go', 'employment', 'put to work', 'process', 'bring', 'workplace', 'toil', 'coursework', 'forge', 'make', 'labour', 'housewifery', 'service', 'exchange', 'studio', 'answer', 'workpiece', 'spadework', 'ironwork', 'leatherwork', 'lacework', 'employ', 'metalwork', 'paperwork', 'nightwork', 'writing', 'welfare work', 'lacquerware', 'learning', 'masterpiece', 'silverwork', 'task', 'workload', 'crop', 'run', 'operate', 'function', 'wreak', 'work on', 'act', 'puzzle out', 'make for', 'piece of work', 'do work', 'project', 'deal', 'work ethic', 'deal', 'exploit', 'overwork', 'worker', 'housekeeping', 'business', 'task', 'employment', 'vocation', 'money', 'subcontract', 'profession', 'career', 'employer', 'place', 'duty', 'workplace', 'hire', 'internship', 'problem', 'chore', 'volunteer', 'position', 'laborer', 'handyman', 'occupation', 'application', 'appointment', 'computing'], \n",
    "    'school' : ['school', 'education', 'university', 'academy', 'college', 'teacher', 'classroom', 'grammar school', 'student', 'primary school', 'secondary school', 'educate', 'vocational school', 'seminary', 'schoolhouse', 'kindergarten', 'educational institution', 'conservatory', 'day school', 'shoal', 'public school', 'elementary school', 'private school', 'middle school', 'graduate school', 'curriculum', 'academic', 'gymnasium', 'schoolteacher', 'lyceum', 'deconstructivism', 'schoolroom', 'institution', 'survey', 'learn', 'read', 'research', 'report', 'analyze', 'compary', 'essay', 'major', 'memorizer', 'science', 'learning', 'examination', 'graduation', 'review', 'concentration', 'memorise', 'discipline', 'field of study', 'subject field', 'subject area', 'graduate', 'knowledge', 'researchers', 'analysis', 'schoolwork', 'preparation', 'homework', 'coursework', 'tutoring', 'typing', 'teaching', 'prep', 'lesson', 'tutorial', 'basics', 'housework', 'kids', 'math', 'errands', 'assignments', 'preschool', 'tasks', 'exams', 'paperwork', 'mathematics', 'english', 'history', 'literature', 'thesis', 'fail', 'delay', 'language', 'geography', 'course' ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-106f8579bdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_journal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_journal_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description_split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription_split\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_journal_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal' is not defined"
     ]
    }
   ],
   "source": [
    "df_journal = df_journal.dropna(subset = ['id'])\n",
    "df_journal_lang = df_journal\n",
    "df_journal_lang['description_split'] = df_journal_lang['description'].str.rsplit()\n",
    "df_journal_lang['length'] = df_journal_lang.description_split.str.len() \n",
    "df_journal_lang = df_journal_lang[df_journal_lang['length'] > 20]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "def lemma1(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "\n",
    "def lemma2(word):\n",
    "    return WordNetLemmatizer().lemmatize(word,'v')\n",
    "\n",
    "def prepare_text(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 2] #check what works best \n",
    "    #tokens = [porter.stem(token) for token in tokens] #stemming\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [lemma1(token) for token in tokens] #lemmatization \n",
    "    tokens = [lemma2(token) for token in tokens] #lemmatization verbs\n",
    "    return tokens\n",
    "\n",
    "def prepare_topics(topics):\n",
    "    for topic in topics: \n",
    "        prepared_words = [] \n",
    "        for string in topics[topic]:\n",
    "            string = prepare_text(string)\n",
    "            prepared_words.append(string)\n",
    "            res = []\n",
    "            [res.append(x) for x in prepared_words if x not in res] \n",
    "            res = [' '.join(map(str, i)) for i in res]\n",
    "        topics[topic] = res\n",
    "    return topics \n",
    "\n",
    "def sentiment_analyzer(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    negative_score = score['neg']\n",
    "    positive_score = score['pos']\n",
    "    neutral_score = score['neu']\n",
    "    difference = abs(negative_score - positive_score)\n",
    "    if neutral_score > 0.8:\n",
    "        return 'neutral'\n",
    "    elif difference <0.1:\n",
    "        return 'neutral'\n",
    "    elif negative_score > positive_score:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "def dutch_translator(text):\n",
    "    result = translator.translate(text, dest='en',  src='nl')\n",
    "    return result.text\n",
    "\n",
    "def eng_translator(text):\n",
    "    result = translator.translate(text, dest='nl',  src='en')\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_journal_lang' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-47a8893e7f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description_eng'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdutch_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tag'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdutch_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prepared_description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepare_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription_eng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_journal_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sc_description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description_split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_journal_lang' is not defined"
     ]
    }
   ],
   "source": [
    "df_journal_lang['description_eng'] = df_journal_lang.apply(lambda row: dutch_translator(row.description), axis = 1)\n",
    "df_journal_lang['tag'] = df_journal_lang.apply(lambda row: dutch_translator(row.tag), axis = 1)\n",
    "df_journal_lang['prepared_description'] = df_journal_lang.apply(lambda row: prepare_text(row.description_eng), axis = 1)\n",
    "df_journal_lang = df_journal_lang.drop(['timestamp', 'rating', 'sc_description', 'length', 'description_split'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journal_lang.to_excel('prepared_journal_model2_lang.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3ae120489bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepared_topics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description_eng'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdutch_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prepared_description'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprepare_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription_eng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_journal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_journal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sc_description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description_split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_journal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_topics' is not defined"
     ]
    }
   ],
   "source": [
    "prepared_topics = prepare_topics(topics)\n",
    "df_journal['description_eng'] = df_journal.apply(lambda row: dutch_translator(row.description), axis = 1)\n",
    "df_journal['prepared_description'] = df_journal.apply(lambda row: prepare_text(row.description_eng), axis = 1)\n",
    "df_journal = df_journal.drop(['timestamp', 'rating', 'sc_description', 'length', 'description_split'], axis = 'columns')\n",
    "display(df_journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_journal.to_excel('prepared_journal_model2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
